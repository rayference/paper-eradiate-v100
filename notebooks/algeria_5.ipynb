{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Setup and visualization of a digital elevation model\n",
    "\n",
    "**Important:** This example requires additional data which can be downloaded with the following command-line call: `python download.py algeria`.\n",
    "\n",
    "In this example, we demonstrate how to set up minimal infrastructure to add a triangulated digital elevation model (DEM) to an Eradiate simulation. We use the expert interface to create RGB images of the Algeria-5 pseudo-invariant calibration site.\n",
    "\n",
    "This notebook assumes that the data required for the simulations is available at the root of the repository, in a `data` subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with a few imports.\n",
    "import eradiate\n",
    "\n",
    "# In addition to Eradiate, we need:\n",
    "# - matplotlib to plot our results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# - Numpy and xarray for vectorized array calculus\n",
    "import numpy as np\n",
    "\n",
    "# - Mitsuba (Eradiate's radiometric kernel) to use the expert interface\n",
    "import mitsuba as mi\n",
    "\n",
    "# We also import a few Eradiate types that will be used in the following:\n",
    "from eradiate import KernelContext, fresolver\n",
    "from eradiate import unit_registry as ureg\n",
    "from eradiate.kernel import (\n",
    "    KernelSceneParameterFlags,\n",
    "    SceneParameter,\n",
    "    SearchSceneParameter,\n",
    ")\n",
    "from eradiate.scenes.spectra import InterpolatedSpectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's do a bit of preparation. We first select an Eradiate mode\n",
    "# (that should be done as early as possible in the computational workflow):\n",
    "eradiate.set_mode(\"mono\")\n",
    "\n",
    "# Next, we add the data directory to the file resolver.\n",
    "fresolver.append(\"../data\")\n",
    "\n",
    "# Finally, we adjust the plotting style (optional)\n",
    "eradiate.plot.set_style()\n",
    "plt.style.use(\"eradiate.mplstyle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Now that the basic environment setup is complete, let's briefly introduce the scene build method.\n",
    "\n",
    "* We will use a **spherical-shell geometry** for the atmosphere, and we assume a spherical geoid surface.\n",
    "* Eradiate centers the planetary surface (a sphere of radius *r* = 6378.1 km) at the origin (0, 0, 0) and positions sensors by default at the North Pole.\n",
    "* The DEM has already been triangulated as a mesh stored in the PLY format. The mesh was extracted from the Copernicus GLO-30 dataset, and vertices were already moved to position the reference at the North Pole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We retrieve the radius of the sphere used as the geoid. Mesh vertex positions\n",
    "# are given in metres, so we won't change the default kernel units, and we will\n",
    "# program everything in metres.\n",
    "earth_radius = eradiate.constants.EARTH_RADIUS.m_as(\"m\")\n",
    "\n",
    "# When creating the mesh, the elevation data in the DEM dataset was applied\n",
    "# relative to the geoid. Therefore, there is an offset between the geoid level\n",
    "# and the actual surface. We define the location of the reference point in the\n",
    "# scene, accounting for the elevation of the site, in local East-North-Up (ENU)\n",
    "# coordinates. The center of the Algeria-5 site is approximately located at\n",
    "# 31.02N 2.23E, with an elevation of 530 m.\n",
    "# We also store the location ENU frame vectors for convenience:\n",
    "site_center = [0, 0, earth_radius + 530.0] * ureg.m\n",
    "site_center_north = np.array([0, 1, 0])\n",
    "site_center_east = np.array([1, 0, 0])\n",
    "site_center_up = np.array([0, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "**Note:** For more advanced positioning, the [pymap3d](https://github.com/geospace-code/pymap3d/) library provides a convenience interface to transform geodetic coordinates into ECEF, ENU or other coordinate systems.\n",
    "\n",
    "Now, let's define the various objects that will reflect light in our scene. We do this through Eradiate's expert interface, using Mitsuba primitives directly. We store these definitions in a *kernel dictionary*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_ply = fresolver.resolve(\n",
    "    # \"ply/algeria_5.ply\"  # Full resolution (30 m)\n",
    "    \"ply/algeria_5x3.ply\"  # Downsampled 3 times (90 m), default for best speed\n",
    ")\n",
    "fname_ply = str(\n",
    "    fname_ply\n",
    ")  # Cast to str (Mitsuba does not accept pathlib.Path instances)\n",
    "\n",
    "kdict = {\n",
    "    # First, materials. We have only one (a diffuse BRDF for sand, which\n",
    "    # we will apply to both the triangulated DEM and the background planetary\n",
    "    # surface). We have to be careful with the identification of the various\n",
    "    # entries in the scene tree: Mitsuba parses the scene dictionary in the\n",
    "    # alphanumerical order of the dictionary keys, and we want materials to be\n",
    "    # processed first.\n",
    "    \"01_mat_sand\": {\n",
    "        \"type\": \"diffuse\",\n",
    "        \"id\": \"01_mat_sand\",  # For safety, make this consistent with the dict key\n",
    "    },\n",
    "    # Next, shapes. We have the DEM first, then the background sphere.\n",
    "    \"02_shape_algeria-5\": {\n",
    "        \"type\": \"ply\",\n",
    "        \"filename\": fname_ply,\n",
    "        \"face_normals\": True,  # Very important: do not interpolate surface normals to avoid visual artefacts\n",
    "        \"bsdf\": {\n",
    "            \"type\": \"ref\",\n",
    "            \"id\": \"01_mat_sand\",\n",
    "        },  # Reference the previously defined material\n",
    "    },\n",
    "    \"02_shape_background\": {\n",
    "        \"type\": \"sphere\",\n",
    "        \"radius\": earth_radius,  # Mitsuba does not support units the way Eradiate does: this is why we needed to convert EARTH_RADIUS to metres\n",
    "        \"bsdf\": {\n",
    "            \"type\": \"ref\",\n",
    "            \"id\": \"01_mat_sand\",\n",
    "        },  # Reference the previously defined material\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "If we'd perform a radiative transfer simulation on this only, the surface would appear white: we need to input the spectral variations of the sand BRDF's reflectance. Let's first start by loading some spectral data, which we will extract from an RPV parameter dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the reflectance spectrum data\n",
    "reflectance = fresolver.load_dataset(\"bsdf/rpv_sand.nc\")[\"rho_0\"]\n",
    "\n",
    "# Initialize an InterpolatedSpectrum object to get a convenient interface to\n",
    "# evaluate the spectrum (we will used its eval() method right after that)\n",
    "sand_spectrum = InterpolatedSpectrum.from_dataarray(dataarray=reflectance)\n",
    "\n",
    "\n",
    "# Encapsulate the call to InterpolatedSpectrum.eval() in function that can be\n",
    "# used directly to declare a kernel parameter in the expert interface\n",
    "def sand_reflectance(ctx: KernelContext) -> float:\n",
    "    return sand_spectrum.eval(ctx.si).m_as(\"dimensionless\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We must let Eradiate know that at every iteration of the spectral loop, it has to update the kernel object that holds the reflectance of the sand using these data, based on the spectral context of the current loop iteration. We define this *update protocol* using the `SceneParameter` class. In that case, it should encapsulate a callable with signature `f(ctx: KernelContext) -> float`, which returns the value of the reflectance for the given kernel context (which, among others, holds information about the current spectral loop iteration).\n",
    "\n",
    "In addition, it contains metadata that helps Mitsuba find which kernel-level parameter is associated to the callable. This is required because the way Mitsuba exposes scene parameters is currently fragile and might be unreliable if those hints are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpmap = {\n",
    "    # This key is arbitrary. For clarity, however, we set it consistent with\n",
    "    # the expected parameter path\n",
    "    \"01_mat_sand.reflectance.value\": SceneParameter(\n",
    "        sand_reflectance,\n",
    "        search=SearchSceneParameter(\n",
    "            node_type=mi.BSDF,  # The type of the node in the Mitsuba scene tree that is expected to hold the parameter\n",
    "            node_id=\"01_mat_sand\",  # The ID of the node in the Mitsuba scene tree that is expected to hold the parameter\n",
    "            parameter_relpath=\"reflectance.value\",  # The parameter ID, relative to the node in the Mitsuba scene tree that is expected to hold the parameter\n",
    "        ),\n",
    "        flags=KernelSceneParameterFlags.SPECTRAL,  # This flag tells Eradiate that this parameter has to be updated at each iteration of the spectral loop\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Debugging ill-defined parameters can be difficult without basic knowledge of Mitsuba. For an introduction, see the [Mitsuba documentation](https://mitsuba.readthedocs.io/).\n",
    "\n",
    "With that done, we can now move on to setting up our illumination and sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These illumination parameters are arbitrary. You can use a library like skyfield\n",
    "# to get the local ephemeris and set them to more realistic values.\n",
    "illumination = {\"type\": \"directional\", \"zenith\": 30.0, \"azimuth\": 200.0}\n",
    "\n",
    "# We position a camera looking at the target center, from 1 km East, 50 m above\n",
    "# the reference point's altitude.\n",
    "t = site_center.m\n",
    "o = t + site_center_east * 1000.0 + site_center_up * 50.0\n",
    "u = site_center_up\n",
    "measure = {\n",
    "    \"type\": \"perspective\",\n",
    "    # \"film_resolution\": (160, 80),  # Fast preview\n",
    "    \"film_resolution\": (750, 375),  # Medium resolution\n",
    "    # \"film_resolution\": (1500, 750),  # High resolution\n",
    "    \"far_clip\": 1e20,  # Set it to a very large value to prevent any clipping\n",
    "    \"target\": t,\n",
    "    \"origin\": o,\n",
    "    \"up\": u,\n",
    "    \"srf\": {\n",
    "        \"type\": \"delta\",\n",
    "        \"wavelengths\": [440, 550, 660],  # We process 3 channels to create an RGB image\n",
    "    },\n",
    "}\n",
    "\n",
    "# We define a basic atmosphere with a thin aerosol layer\n",
    "atmosphere = {\n",
    "    \"type\": \"heterogeneous\",\n",
    "    \"molecular_atmosphere\": {\"type\": \"molecular\"},\n",
    "    \"particle_layers\": {\n",
    "        \"type\": \"particle_layer\",\n",
    "        \"bottom\": 0.0,\n",
    "        \"top\": 10e3,\n",
    "        \"distribution\": {\"type\": \"exponential\"},\n",
    "        \"tau_ref\": 0.1,\n",
    "        \"dataset\": \"govaerts_2021-desert\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Now, we can create an `AtmosphereExperiment` that will incorporate the Mitsuba primitives created with the expert interface, the background 1D, spherical-shell atmosphere, the illumination and measure we defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = eradiate.experiments.AtmosphereExperiment(\n",
    "    geometry=\"spherical_shell\",\n",
    "    surface=None,  # Important: remove the automatic surface (we took care of it manually)\n",
    "    atmosphere=atmosphere,\n",
    "    illumination=illumination,\n",
    "    measures=measure,\n",
    "    kdict=kdict,\n",
    "    kpmap=kpmap,\n",
    ")\n",
    "\n",
    "# We immediately initialize the simulation. This will load the kernel scene and\n",
    "# initialize internal data structures required for efficient ray tracing. Larger\n",
    "# meshes will take more time to initialize.\n",
    "exp.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "We can run the simulation. The default sample count is low so it finishes quickly on most machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "spp = 16  # Quick preview\n",
    "# spp = 1024  # Nice render with low noise\n",
    "result = eradiate.run(exp, spp=spp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Now that the computation is finished, we can use the `dataarray_to_rgb()` helper to visualize the RGB image we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = (\n",
    "    eradiate.xarray.interp.dataarray_to_rgb(\n",
    "        result.squeeze()[\"radiance\"],\n",
    "        channels=[(\"w\", 660), (\"w\", 550), (\"w\", 440)],\n",
    "        gamma_correction=True,\n",
    "    )\n",
    "    * 1.8  # Adjust brightness with this multiplier\n",
    ")\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Tips:\n",
    "\n",
    "* To iterate faster when building the scene, remove as much detail as possible (*e.g.* remove the atmosphere and DEM to check it your material is correctly configured; use a coarse version of the surface mesh if available).\n",
    "\n",
    "What to do next:\n",
    "\n",
    "* Move the camera to a high altitude position (*e.g.* around 100 km), point it down and adjust its field of view to get a nadir view of the site.\n",
    "* Load the native-resolution DEM triangulation and compare the recorded reflected radiance with the low-resolution one.\n",
    "* Remove the `kpmap` from the simulation: the surface should now appear white because there is no longer a way for Eradiate to know how to update the scene reflectance at each iteration of the spectral loop.\n",
    "* Replace the diffuse BRDF with the RPV BRDF.\n",
    "* Apply the reflectance computation techniques discussed in the dedicated example to this 3D site."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
